{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "381cf4e3-b0c5-4b53-b055-650c23a3bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from stackapi import StackAPI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92090346-3b42-4b76-8ac8-c8f7f004bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"alpaca\", \"bloom\", \"cerebras-gpt\", \"chatglm\", \"chinchilla\", \"codex\", \"codegen\", \"codegx\", \"dolly-v2\", \"eleuther-pythia\", \"falcon\", \"fastchat-t5\", \"gal\", \"gpt-3\", \"gpt-3.5\", \"gpt-4\", \"gpt4all\", \"gpt-neox\", \"gpt-j\", \"koala\", \"llama\", \"mpt\", \"oasst-pythia\", \"opt\", \"palm\", \"palm-coder\", \"replit-code-v1\", \"stablelm-base-alpha\", \"stablelm-tuned-alpha\", \"starcoder-base\", \"starcoder\", \"vicuna\", \"llama-2\"]\n",
    "topics = [\"large-language-models\", \"llm\", \"word-embedding\", \"gpt\", \"intelligent-agent\"]\n",
    "tags = models + topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74fc75c7-1942-45e1-bd07-cf3dd5a2a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE = StackAPI('ai', key=\"GXK03oiqVULDxPyWtLmyNA((\")\n",
    "# q_blocks = {}\n",
    "# for tag in tqdm(tags):\n",
    "#     questions = SITE.fetch('questions', tagged=tag, sort = 'votes', filter='withbody')\n",
    "    \n",
    "#     for question in questions['items']:\n",
    "#         content = BeautifulSoup(question['body']).get_text()\n",
    "#         q_blocks[question['question_id']] = {\"link\": question['link'], \"metadata\": question, \"title\": question[\"title\"], \"content\": content, \"question_id\": question['question_id']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ff3ec40-3406-40f8-af7e-e41a1d3c7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE = StackAPI('genai', key=\"GXK03oiqVULDxPyWtLmyNA((\")\n",
    "# questions = SITE.fetch('questions', sort = 'votes', filter='withbody')\n",
    "# for question in questions['items']:\n",
    "#     content = BeautifulSoup(question['body']).get_text()\n",
    "#     q_blocks[question['question_id']] = {\"link\": question['link'], \"metadata\": question, \"title\": question[\"title\"], \"content\": content, \"question_id\": question['question_id']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "752c87da-267c-4b45-8392-0da6a25afe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 258/258 [00:52<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "for question_id, q_block in tqdm(examples.items()):\n",
    "    answers = SITE.fetch('questions/{ids}/answers', ids = [question_id], sort = 'votes', filter='withbody')\n",
    "    \n",
    "    # Find top voted answers\n",
    "    if q_block.get(\"answers\") is None:\n",
    "        q_block['answers'] = []\n",
    "    for item in answers['items']:\n",
    "        body = BeautifulSoup(item['body']).get_text()\n",
    "        q_block['answers'].append({\"answer_id\": item['answer_id'], \"body\": body, \"score\": item['score'], \"is_accepted\": item[\"is_accepted\"]}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97a903-eecf-44a8-b13d-5a8c8a8ad6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61790f6-578c-4802-a92b-f1ce4ba7b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered = {}\n",
    "# for idx, (qid, q_block) in enumerate(q_blocks.items()):\n",
    "#     keywords = [\"chatgpt\", \"image\", \"stable diffusion\", \"draw\", \"deep-RL\", \".net\", \"RL\", \"nasty\", \"AUTOMATIC1111\"]\n",
    "#     skip = False\n",
    "#     for keyword in keywords:\n",
    "#         if keyword.lower() in q_block['title'].lower() or keyword.lower() in q_block['content'].lower():\n",
    "#             skip = True\n",
    "#     if skip:\n",
    "#         continue\n",
    "#     print(f\"title: {q_block['title']}\\n\")\n",
    "#     print(f\"content: {q_block['content'][:250]}...\\n\")\n",
    "#         # print(f\"answers: {q_block['answers']}\")\n",
    "#     filtered[qid] = q_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7311c4-3edf-4bbe-ad5c-0d660ba625dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "69f63e6b-e53f-46be-98e3-c88b7cf5dd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(filtered, open(\"aistackexchange.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "220bafa1-f683-49ce-9d23-861b30f9205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "examples = json.load(open(\"aistackexchange.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19cc6d87-691f-453c-9193-142a9143cfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['32477', '27761', '39619', '34243', '30157', '39933', '37283', '39050', '38167', '37929', '36964', '35444', '27261', '39296', '37205', '41879', '41178', '41153', '41119', '39757', '39409', '36422', '39738', '40302', '41214', '40848', '40300', '39863', '40179', '39840', '41277', '39249', '39186', '40486', '40111', '41066', '41728', '40839', '39579', '41249', '40519', '40592', '41154', '40370', '39652', '41149', '39795', '41887', '41842', '41793', '41792', '41778', '41770', '41643', '41588', '41393', '41355', '41295', '41247', '41184', '41179', '41087', '40906', '40883', '40704', '40600', '40478', '40281', '40224', '39873', '41293', '11285', '26235', '39151', '5408', '28011', '26739', '17403', '6144', '12656', '11511', '37542', '32377', '23162', '40443', '13926', '3805', '22413', '21119', '6571', '20911', '16553', '12896', '11833', '28065', '13045', '11178', '24856', '15490', '40390', '40273', '28089', '15676', '5285', '39021', '32715', '26794', '23159', '18098', '11825', '11328', '39584', '34068', '32485', '28353', '28321', '26667', '26284', '24075', '23217', '22700', '20977', '18369', '17425', '14325', '37472', '27957', '40134', '21347', '15463', '41823', '41002', '40785', '40463', '39658', '39276', '38980', '37195', '37146', '37076', '35225', '32721', '26440', '26405', '26218', '11236', '22673', '27038', '24831', '10869', '16516', '40140', '7684', '40360', '22581', '23418', '40232', '27254', '27947', '25369', '22734', '39817', '17992', '17930', '13862', '11621', '22877', '15965', '37148', '27044', '39999', '39740', '39111', '22469', '40483', '37326', '20591', '41582', '41581', '40679', '40476', '40418', '40045', '38973', '36924', '32667', '32436', '40385', '15', '1694', '17025', '3243', '6', '7774', '7793', '3406', '1515', '26956', '2668', '4489', '5059', '2547', '8637', '2917', '8707', '12506', '25725', '22323', '18290', '3364', '12991', '23838', '26944', '6407', '18791', '8048', '15695', '6504', '4037', '8920', '20663', '36160', '30338', '27233', '20889', '18088', '37888', '36555', '32098', '23977', '23098', '9794', '6431', '35893', '226', '24', '105', '45', '293', '151', '218', '34', '59', '251', '5', '67', '395', '397', '219', '318', '347', '252', '260', '312', '315', '380', '393', '389'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe5eef64-5431-44ee-9e6a-c6e23cf562db",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted = []\n",
    "for q in examples.values():\n",
    "    # if q['metadata'].get('accepted_answer_id'):\n",
    "        # print(q['metadata'].keys())\n",
    "    for answer in q['answers']:\n",
    "        if answer['is_accepted']:\n",
    "            accepted.append(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3947012a-6c09-4d07-b0da-92e6c6e15be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d96f518c-9154-4d84-9c75-536ac1c243e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_idxs = [25, 47, 48, 49,54, 55, 58, 60, 62, 70, 75, 78]\n",
    "specific_idxs = [0, 1, 2, 7, 23, 24, 36, 37, 38, 41, 42, 51, 52, 53, 67, 72]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ede00cff-b92f-47ee-a4f2-cd695615460e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #                     {\n",
    "#                         \"buyer_name\": buyer_name,\n",
    "#                         \"question\": question,\n",
    "#                         \"gold_block_id\": block.block_id,\n",
    "#                         \"gold_block_text\": block.content,\n",
    "#                     }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a0507-fad2-4fec-a87e-d767af09d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "    document_id: str\n",
    "    document_title: str\n",
    "    section_title: str\n",
    "    publication_date: str\n",
    "    token_start: int\n",
    "    token_end: int\n",
    "    content: str\n",
    "    questions: List[str] = field(default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf78864d-3966-421b-89d6-4f5e1355b199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer_id': 261,\n",
       "  'body': 'It\\'s probably still valid. LLM stands for large language model -- it models its training data by predicting the next (or any masked) tokens given the context.\\nI tend to be a bigger fan of the \"simulators\" analogy as e.g., thinking about LLMs as \"agents\" tends to add too much anthropomorphism which clouds my intuition regarding these models.\\nAdditionally, it still holds true that LLMs are trained on vast amounts of heterogenous data, meaning that it simultaneously models a plethora of types and styles of text.\\nHowever, such models are additionally instruction-tuned on conversational data, allowing the user to interact with the model in a more chat-bot-style way. It could be that, with this instruction-tuning, such models can no longer adequately model the diverse styles of text-data found in its pretraining dataset. It would depend on the diversity of model generations.\\nAt least with Llama 2, you can manipulate the style of the assistant-style responses with a system prompt, suggesting that that method of instruction-tuning still allows for some variation in text-completions to be kept.\\n',\n",
       "  'score': 2,\n",
       "  'is_accepted': True},\n",
       " {'answer_id': 261,\n",
       "  'body': 'It\\'s probably still valid. LLM stands for large language model -- it models its training data by predicting the next (or any masked) tokens given the context.\\nI tend to be a bigger fan of the \"simulators\" analogy as e.g., thinking about LLMs as \"agents\" tends to add too much anthropomorphism which clouds my intuition regarding these models.\\nAdditionally, it still holds true that LLMs are trained on vast amounts of heterogenous data, meaning that it simultaneously models a plethora of types and styles of text.\\nHowever, such models are additionally instruction-tuned on conversational data, allowing the user to interact with the model in a more chat-bot-style way. It could be that, with this instruction-tuning, such models can no longer adequately model the diverse styles of text-data found in its pretraining dataset. It would depend on the diversity of model generations.\\nAt least with Llama 2, you can manipulate the style of the assistant-style responses with a system prompt, suggesting that that method of instruction-tuning still allows for some variation in text-completions to be kept.\\n',\n",
       "  'score': 2,\n",
       "  'is_accepted': True}]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187e741-ce91-40f5-a991-bb707c460b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d953fbdc-99b5-449f-8ad3-d57d28c1d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "answer_count = defaultdict(int)\n",
    "selected_questions = []\n",
    "for idx, x in enumerate(accepted):\n",
    "    qtype = \"general\" if idx in general_idxs else \"specific\"\n",
    "    x['question_type'] = qtype\n",
    "    x['question'] = x['title'] + \"\\n\\n\" + x['content']\n",
    "    answer_count[qtype] += len(x['answers'])\n",
    "    x['buyer_name'] = x['link']\n",
    "    for aidx, answer in enumerate(x['answers']):\n",
    "        if answer['is_accepted']:\n",
    "            x['gold_block'] = {\"document_id\": x['question_id'], \"document_title\": x['title'], \"section_title\": \"\", \"publication_date\": x['metadata']['creation_date'], \"token_start\": 0, \"token_end\": len(answer['body']), \"content\": answer['body'], \"questions\": x['title']}\n",
    "            x['gold_block_id'] = answer['answer_id']\n",
    "    selected_questions.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd362cf-4d2e-42a9-b8c0-40b0b47a6eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4bf4233e-0532-4ab9-95ab-884f1789e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(selected_questions, open(\"se_questions.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b4457f9-37ac-4840-929d-d19441004e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'specific'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_questions[0]['question_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6e2c253-f363-416f-9432-d5368ed30b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = json.load(open(\"../data/final_dataset_with_metadata.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f4b0f-f882-48c5-9995-8ee367f263e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv_id, data\n",
    "# 'metadata', 'blocks'\n",
    "# each block; 'questions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e37408f-7529-45bd-84f7-3e2c1d50e3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the name of the architecture that has dominated natural language processing (NLP) benchmarks in recent years?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['2212.14882']['blocks'][0]['questions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caccdf0-1cad-4a1a-b409-213ded02ae3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
