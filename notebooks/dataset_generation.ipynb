{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "005ca3bf-4bce-4948-8975-265dc3a96c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/lustre/home/nrahaman/python/info-bazaar\")\n",
    "sys.path.append(\"/network/scratch/w/weissmar/tn/info-bazaar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdd05faf-1793-4d17-bb2f-7aa7572845bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import guidance\n",
    "\n",
    "from bazaar.lem_utils import LLaMa2, clean_block_content\n",
    "from bazaar.lem_utils import clean_program_string, get_llm\n",
    "from bazaar.lem_utils import get_llm\n",
    "import transformers\n",
    "import bitsandbytes\n",
    "from torch import cuda, bfloat16\n",
    "import tiktoken\n",
    "import re\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "import matplotlib.pyplot as plt\n",
    "import json \n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "be12bcca-79c0-42bf-a26f-4bc7865d5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4\"\n",
    "rm_comments = re.sub(r\"(?<!\\\\)%.*$\", \"\", data['paper'], flags=re.MULTILINE)\n",
    "\n",
    "# Remove unnecessary information (here we remove the documentclass line as an example)\n",
    "rm_unnecessary = re.sub(r\"\\\\documentclass[^\\n]*\\n\", \"\", rm_comments)\n",
    "\n",
    "# Split by sections\n",
    "# removed_labels = re.sub(r\"\\\\label\\{.*?\\}\", \"\", rm_unnecessary)\n",
    "# content_emph = re.sub(r\"\\\\emph\\{(.*?)\\}\", r\"\\1\", removed_labels)\n",
    "# content_emph = re.sub(r\"\\{\\\\emph (.*?)\\}\", r\"\\1\", content_emph)\n",
    "# content_it = re.sub(r\"\\\\textit\\{(.*?)\\}\", r\"\\1\", content_emph)\n",
    "# content_bf = re.sub(r\"\\\\textbf\\{(.*?)\\}\", r\"\\1\", content_it)\n",
    "# content_ul = re.sub(r\"\\\\underline\\{(.*?)\\}\", r\"\\1\", content_bf)\n",
    "\n",
    "split_by_sections = re.split(\n",
    "    r\"(\\\\section\\{.*?\\}|\\\\subsection\\{.*?\\}|\\\\subsubsection\\{.*?\\})\", rm_unnecessary\n",
    ")\n",
    "\n",
    "all_blocks = []\n",
    "for i in range(1, len(split_by_sections), 2):\n",
    "    section_title = re.search(\n",
    "        r\"(\\\\section|\\\\subsection|\\\\subsubsection)\\{(.*?)(\\\\label\\{.*?\\})?\\}\",\n",
    "        split_by_sections[i],\n",
    "    ).group(2)\n",
    "    section_title = LatexNodes2Text().latex_to_text(section_title.strip())\n",
    "    content = split_by_sections[i + 1]\n",
    "\n",
    "    # Separate figures and equations from the text\n",
    "    # content_without_figures = re.sub(\n",
    "    #     r\"(\\\\begin\\{figure\\}.*?\\\\end\\{figure\\})\",\n",
    "    #     \"\",\n",
    "    #     content,\n",
    "    #     flags=re.DOTALL,\n",
    "    # )\n",
    "\n",
    "    # Remove tags\n",
    "    # content_without_tags = re.sub(r\"\\\\[^{]*\\{.*?\\}\", \"\", content_without_figures_equations)\n",
    "    content_no_lone_newlines = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", content)\n",
    "    content_no_double_newlines = re.sub(r\"\\n\\n\", \"\\n\", content_no_lone_newlines)\n",
    "\n",
    "\n",
    "    content_cite = re.sub(r\"\\\\citep\\{(.*?)\\}\", r\"[\\1]\", content_no_double_newlines)\n",
    "    content_cite = re.sub(r\"\\\\citet\\{(.*?)\\}\", r\"[\\1]\", content_cite)\n",
    "    content_cite = re.sub(r\"\\\\cite\\{(.*?)\\}\", r\"[\\1]\", content_cite)\n",
    "    block = LatexNodes2Text().latex_to_text(content_cite).strip()\n",
    "    # block = content_cite.strip()\n",
    "    num_tokens = len(tiktoken.encoding_for_model(model_name).encode(block))\n",
    "    if num_tokens == 0:\n",
    "        continue\n",
    "    all_blocks.append(\n",
    "        {\n",
    "            \"block_id\": f\"{arxiv_id}/{section_title}/{idx}\",\n",
    "            \"content\": block,\n",
    "            \"num_tokens\": num_tokens,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f3fd8771-321c-439b-8e75-f2bceb01ee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d978e89d-e445-46e9-90c4-f26a49671605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "':appendix_architecture}.\\n\\n\\\\subsubsection{Residual Block}\\\\label{sec:expt_blocktype}\\n\\\\begin{table}[!htb]\\n    \\\\let\\\\center\\\\empty\\n    \\\\let\\\\endcenter\\\\relax\\n    \\\\centering\\n    \\\\resizebox{0.9\\\\textwidth}{!}{\\\\input{tables/RBs.tex}}\\n    \\\\caption{\\\\label{tab:RBs}DA MSE variation with residual block in models trained for 150 epochs.}\\n\\\\end{table} \\nIn this experiment we investigated the effect of RB type on our pool of architectures. We found that no single RB was superior for all systems but, for a given archi'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = data['paper'].find(\"DA MSE variation with residual\")\n",
    "data['paper'][index-250: index+250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d061b20-1307-448f-9d51-abe3b106f052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "190d8868-3321-42c5-91ee-e6677345788a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'block_id': '2101.02121/Discussion/2',\n",
       "  'content': 'In this section we briefly discuss a few points raised in the course of this research.',\n",
       "  'num_tokens': 17},\n",
       " {'block_id': '2101.02121/Architecture Search Details/2',\n",
       "  'content': 'In this appendix, we give details of our architecture search that would be out of place in the main text.',\n",
       "  'num_tokens': 22}]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in all_blocks if x['num_tokens'] < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5f4719f1-8ee5-43e5-adff-d9f7d678bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [block['content'] for block in all_blocks if block['num_tokens'] < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "90949551-e440-41e1-bd72-2207663b53e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 0., 3., 3., 2., 6., 4., 1., 3., 1., 0., 4., 3., 1., 2., 2., 0.,\n",
       "        2., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 2.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.]),\n",
       " array([  17.  ,   48.16,   79.32,  110.48,  141.64,  172.8 ,  203.96,\n",
       "         235.12,  266.28,  297.44,  328.6 ,  359.76,  390.92,  422.08,\n",
       "         453.24,  484.4 ,  515.56,  546.72,  577.88,  609.04,  640.2 ,\n",
       "         671.36,  702.52,  733.68,  764.84,  796.  ,  827.16,  858.32,\n",
       "         889.48,  920.64,  951.8 ,  982.96, 1014.12, 1045.28, 1076.44,\n",
       "        1107.6 , 1138.76, 1169.92, 1201.08, 1232.24, 1263.4 , 1294.56,\n",
       "        1325.72, 1356.88, 1388.04, 1419.2 , 1450.36, 1481.52, 1512.68,\n",
       "        1543.84, 1575.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([block['num_tokens'] for block in all_blocks], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bbed9-53b1-4c90-9a24-9c5200932901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49977df2-3c52-4f03-9da5-364fdbf9baea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3b419681-feb2-4d8e-98f4-595dfb033879",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_auth = \"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\"\n",
    "model_id = 'meta-llama/Llama-2-70b-chat-hf'\n",
    "cache_dir = \"/Tmp/slurm.3490591.0/\" #\"/network/scratch/w/weissmar/hf_home/\"\n",
    "guidance_cache_dir = \"/Tmp/slurm.3490591.0/gd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1e95fe16-283b-4889-a4b3-8a87416589c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GUIDANCE_CACHE_DIRECTORY\"] = guidance_cache_dir\n",
    "os.environ[\"HF_CACHE_DIRECTORY\"] = cache_dir\n",
    "os.environ[\"HF_AUTH_TOKEN\"] = hf_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "54e28b4b-e37c-49b3-96c6-4ed20b01a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0ce43e2-6a7f-49c1-84a8-207252d583d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3dcde-b2ee-409b-86e1-63dc07dcdc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcc4fbfd-cceb-4142-a915-3d1e4f848767",
   "metadata": {},
   "outputs": [],
   "source": [
    "category=\"machine-learning\"\n",
    "with open(f\"/network/scratch/w/weissmar/tn/info-bazaar/data/{category}/oa_works_w_arxiv.json\", \"r\") as f:\n",
    "    oa_works_w_arxiv = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3a2dd07b-839b-457c-ad7f-0fcd8514fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "for arxiv_id, data in oa_works_w_arxiv.items():\n",
    "    blocks = parse_latex(data[\"paper\"])\n",
    "    token_count = 0\n",
    "    for block in blocks:\n",
    "        block['num_tokens']\n",
    "        \n",
    "    break\n",
    "    # cleaned_block_contents = improve_block_formatting(blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71925a34-2854-4676-85b3-95cedcb59d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3d08a6c2-6b2f-43d1-b980-f4db42a61efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_string = \"\"\"\n",
    "{{#system~}}\n",
    "You are a text formatting bot. You will be provided a list of text passages and you will reply with an exact copy of each input text passage, but with the following (and only the following) modifications:\n",
    "\n",
    "1. Improve use of white space, tabs, and new-lines. This should shorten the passage.\n",
    "2. Remove citations (e.g., Huges et al. [hugesGenerativeAdversarialLearning]).\n",
    "3. Reformat any tabular data into markdown.\n",
    "\n",
    "IMPORTANT: THE CONTENT OF YOUR REPLY MUST BE THE SAME AS THE USER INPUT.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "---{{#each passages}}\n",
    "{{add @index 1}}. {{this}}\n",
    "{{/each}}---\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen \"cleaned_passages\" temperature=0.0}}\n",
    "{{~/assistant}}    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4a66bd3a-e3f1-45f2-8b44-fc0e8c1189e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 15\n",
    "passages = [all_blocks[i]['content'], all_blocks[i+1]['content'], all_blocks[i+2]['content'], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8c9bad01-036d-4aaa-8763-fc2a9dafd561",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, passage in enumerate(passages):\n",
    "    print(f\"Passage {idx + 1}.\\n {passage.strip()}\")\n",
    "    print(\"\\n --- \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2c985804-06ae-4f36-bdb6-466ebed14fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[495, 898, 568]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[all_blocks[0]['num_tokens'], all_blocks[1]['num_tokens'], all_blocks[2]['num_tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1bdf602e-fe65-43b7-84ca-797a9463b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_llm(model_name=\"Llama-2-70b-chat-hf\")\n",
    "# llm = LLaMa2(hf_auth_token=hf_auth, hf_cache_directory=cache_dir, guidance_cache_directory=guidance_cache_dir)\n",
    "\n",
    "\n",
    "program_string = clean_program_string(program_string)\n",
    "program = guidance(program_string, llm=llm, silent=True)  # noqa\n",
    "\n",
    "program_output = program(passages=passages)\n",
    "cleaned_passage = program_output[\"cleaned_passages\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f64d0699-f9d0-4c8f-b69f-ff303140aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Our proposed formulation is equivalent to the mono-space formulation in (<ref>) in that:\n",
      "\n",
      "𝐰^DA = 𝐰_l^DA\n",
      "\n",
      "This is true under three assumptions:\n",
      "\n",
      "* For high-performing autoencoder, we assume that the AE compression is lossless, meaning g(f(x)) = x.\n",
      "* All features in the latent representation 𝐳 are orthonormal as discussed above.\n",
      "* The observation space contains sufficient information to construct a good approximation of the full space x. This is a necessary condition in the creation of the f^o operator in fig:f^o_scheme and is more likely to hold when M is large. This assumption is discussed in more detail in the proof of Lemma 5 below.\n",
      "\n",
      "We will state and prove a series of lemmas to produce the result in (<ref>).\n",
      "\n",
      "Let 𝐰^DA and 𝐰^DA_l denote the solutions of (<ref>) and (<ref>) respectively, we have that\n",
      "\n",
      "𝐰^DA = (I + V^T H^T R^-1HV)^-1V^T H^T R^-1d\n",
      "\n",
      "and\n",
      "\n",
      "𝐰^DA_l = (I + V_l^T  R_l^-1V_l)^-1V_l^T R_l^-1d_l\n",
      "\n",
      "Proof:\n",
      "\n",
      "The gradient of (<ref>) is:\n",
      "\n",
      "∇ J(𝐰) = 𝐰 - V^TH^TR^-1(d - HV𝐰)\n",
      "\n",
      "Setting this to zero and solving for 𝐰 will give the optimal value 𝐰^DA as required to complete the proof:\n",
      "\n",
      "V^TH^TR^-1d = (I + V^T H^T R^-1HV)𝐰^DA\n",
      "\n",
      "𝐰^DA = (I + V^T H^T R^-1HV)^-1V^T H^T R^-1d\n",
      "\n",
      "As the cost functions in (<ref>) and (<ref>) are mathematically equivalent, where each operator is replaced by its latent equivalent\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc2bb5-326d-4e6b-9605-ac9322a730a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "359ef118-7098-4509-ab4a-60f2690f2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_string = \"\"\"\n",
    "{{#system~}}\n",
    "You are a text formatting bot. You will be provided with two text passages and you decide whether or not they contain semantic content that is sufficiently close such that they should be combined. You will simply output True if you believe they should be merged, or False if you do not.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "---{{#each passages}}\n",
    "{{add @index 1}}. {{this}}\n",
    "{{/each}}---\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{gen \"decision\" temperature=0.0}}\n",
    "{{~/assistant}}    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273b097-f941-4b56-9014-028742981b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_string = clean_program_string(program_string)\n",
    "program = guidance(program_string, llm=llm, silent=True)  # noqa\n",
    "\n",
    "program_output = program(passages=passages)\n",
    "cleaned_passage = program_output[\"cleaned_passages\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "1bfd04f8-7039-48d5-b47f-aa73e0a06e33",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2802829335.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[265], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    {{#select \"answer\"}} Yes{{or}} No{{/select}}\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0762e6eb-2368-4e26-ae80-956755dd683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_string = \"\"\"\n",
    "{{#system~}}\n",
    "You are a text formatting bot. You will be provided with one text passage and you decide whether it contains multiple topics. \n",
    "\n",
    "You will output {{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "{{passage}}\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{#select \"answer\"}} True{{or}} False{{/select}}\n",
    "{{#if answer}}{{gen 'index' pattern='[0-9]+'}}{{/if}}\n",
    "{{~/assistant}}    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4da59d65-0ae4-4c41-8634-ca91e091eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_string = clean_program_string(program_string)\n",
    "program = guidance(program_string, llm=llm, silent=True)  # noqa\n",
    "formatted_passage = \"\\n\".join([f\"{i}. {s}\" for i, s in enumerate(passages[0].split(\"\\n\"))])\n",
    "program_output = program(passage=formatted_passage)\n",
    "# cleaned_passage = program_output[\"decision\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e17e39cb-6752-4a98-bddb-8fa26d8805cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "role_start() got an unexpected keyword argument '__ARxG__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/tn/lib/python3.8/site-packages/IPython/core/formatters.py:920\u001b[0m, in \u001b[0;36mIPythonDisplayFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    918\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m     \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/tn/lib/python3.8/site-packages/guidance/_program.py:207\u001b[0m, in \u001b[0;36mProgram._ipython_display_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_displaying_html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# build and display the html\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m html \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_html\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarked_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display_html(html)\n",
      "File \u001b[0;32m~/.conda/envs/tn/lib/python3.8/site-packages/guidance/_program.py:610\u001b[0m, in \u001b[0;36mProgram._build_html\u001b[0;34m(self, text, last)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# wrap role markers in nice formatting\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m display_out \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m{{\u001b[39;49m\u001b[38;5;124;43m!--GMARKER_START_(role|system|user|assistant|function)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m$(.*?)--}}\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m(.*?)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m{{\u001b[39;49m\u001b[38;5;124;43m!--GMARKER_END_(role|system|user|assistant|function)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m$(.*?)--}}\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrole_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDOTALL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# wrap unfinished role markers in nice formatting\u001b[39;00m\n\u001b[1;32m    613\u001b[0m display_out \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m!--GMARKER_START_(role|system|user|assistant|function)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m$(.*?)--}}\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, role_box, display_out, flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mDOTALL)\n",
      "File \u001b[0;32m~/.conda/envs/tn/lib/python3.8/re.py:210\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/tn/lib/python3.8/site-packages/guidance/_program.py:555\u001b[0m, in \u001b[0;36mProgram._build_html.<locals>.role_box\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    552\u001b[0m     role_name \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole_name=([^ ]*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, tag_text)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    554\u001b[0m start_pattern \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mescape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mrole_start(role_name))\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 555\u001b[0m start_pattern_with_name \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mescape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrole_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__ARxG__\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__VAxLUE__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# TODO: make this more general for multiple keyword args\u001b[39;00m\n\u001b[1;32m    556\u001b[0m start_pattern_with_name \u001b[38;5;241m=\u001b[39m start_pattern_with_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__VAxLUE__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[^\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m]*?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ARxG__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[^=]*?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    557\u001b[0m end_pattern \u001b[38;5;241m=\u001b[39m html\u001b[38;5;241m.\u001b[39mescape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mrole_end(role_name))\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: role_start() got an unexpected keyword argument '__ARxG__'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<s>[INST] <<SYS>>\n",
       "You are a text formatting bot. You will be provided with one text passage and you decide whether or not it contains semantic content covering multiple topics. \n",
       "\n",
       "You must output either:you will simply output the line number to split, otherwise output False.\n",
       "</SYS>>\n",
       "\n",
       "\n",
       "\n",
       "0. Our proposed formulation is equivalent to the mono-space formulation in (<ref>) in that: \n",
       "1.     𝐰^DA = 𝐰_l^DA\n",
       "2.   This is true under three assumptions:      \n",
       "3.   * For high-performing autoencoder, we assume that the AE compression is lossless meaning g(f(x)) =  x.      \n",
       "4.   * All features in the latent representation 𝐳 are orthonormal as discussed above.     \n",
       "5.   * The observation space contains sufficient information to construct a good approximation of the full space x. This is a necessary condition in the creation of the f^o operator in fig:f^o_scheme and is more likely to hold when M is large. This assumption is discussed in more detail in the proof of Lemma 5 below. \n",
       "6. We will state and prove a series of lemmas to produce the result in (<ref>).  \n",
       "7. \n",
       "8. Let 𝐰^DA and 𝐰^DA_l denote the solutions of (<ref>) and (<ref>) respectively, we have that \n",
       "9. \n",
       "10.     𝐰^DA = (I + V^T H^T R^-1HV)^-1V^T H^T R^-1d\n",
       "11.  and  \n",
       "12.     𝐰^DA_l = (I + V_l^T  R_l^-1V_l)^-1V_l^T R_l^-1d_l\n",
       "13. \n",
       "14. Proof: \n",
       "15. \n",
       "16. The gradient of (<ref>) is: \n",
       "17.     ∇ J(𝐰)     =       𝐰 - V^TH^TR^-1(d - HV𝐰)\n",
       "18.  Setting this to zero and solving for 𝐰 will give the optimal value 𝐰^DA as required to complete the proof:  \n",
       "19.     V^TH^TR^-1d   =      ( I + V^T H^T R^-1HV)𝐰^DA\n",
       "20.     𝐰^DA   = (I + V^T H^T R^-1HV)^-1V^T H^T R^-1d\n",
       "21. \n",
       "22. \n",
       "23. As the cost functions in (<ref>) and (<ref>)  are mathematically equivalent where each operator is replaced by its latent equivalent in the bi-reduced space formulation and H_l = I, we can write the exact solutions of 𝐰^DA and 𝐰^DA_l in the following form: \n",
       "24.     𝐰^DA   = (I + A)^-1b\n",
       "25.     𝐰_l^DA   = (I + A_l)^-1b_l\n",
       "26.      where, the matrices A and A_l are such that:     \n",
       "27.     A = V^T H^T R^-1HV,\n",
       "28.      \n",
       "29.     A_l = V_l^T  R_l^-1V_l\n",
       "30.      and b and b_l are:     \n",
       "31.     b = V^T H^T R^-1d\n",
       "32.      \n",
       "33.     b_l = V_l^T R_l^-1d_l\n",
       "34.               \n",
       "35.  Let A and A_l be the matrices defined in (<ref>) and in (<ref>) respectively. The following result held:     \n",
       "36.     A =A_l\n",
       "37.  \n",
       "38.  Let b and b_l be the matrices defined in (<ref>) and in (<ref>) respectively. The following result held:     \n",
       "39.     b =b_l\n",
       "40.   The overall result in equation (<ref>) follows directly from Lemmas <ref> and <ref> but to prove these we need two further results in Lemmas <ref> and <ref>.  Let V_l be the reduced matrix as defined in (<ref>), f^o defined in (<ref>), H as in (<ref>) and V as in (<ref>). The followind result held:     \n",
       "41.     V_l = f^o HV\n",
       "42.           Proof of Lemma <ref>:     by definition, we have      \n",
       "43.     V_l  f V\n",
       "44.      then, from (<ref>) we have     \n",
       "45.     V_l ≈ f H^+ HV\n",
       "46.      Then the thesis follows from the definition of f^o in (<ref>):     \n",
       "47.     V_l    = f^o HV .\n",
       "48.     We note that H^+ H acts is an information bottleneck operator in which only information contained in the observation locations is propagated from V.      Here we can assume that f V≈ f H^+ HV due to some weak assumptions:                   \n",
       "49.   * The observation space of size M contains sufficient information to construct a good approximation of the latent representation. This is equivalent to assumption iii) above because, if the observation space contains all information in the full space, by assumption i) it should also contain all information in the latent space. To show why this might be true consider that there must be large redundancies in the full space in order for the CAE framework to have any success. We argue in the following section that, in all practical scenarios, m, S < M. If a state of size m can contain most of the information of a state of size n it is not unlikely that a state of size M might contain the same information. More concretely, in Section <ref> we demonstrate that the Arcucci et al. CVT with TSVD DA method [Arcucci2019a] suffers no degradation in accuracy when just 10% of the total state space is used as observations (M = 0.1n) and there is only a 5% degradation when M = 0.01n.          \n",
       "50.   * The reduced space of size S also contains sufficient information to construct the latent representation of size m. This condition is implied by the lossless compression assumption i) as the reconstruction of the full state passes through the reduced space and the latent space.            \n",
       "51.  Let R_l be the reduced matrix as defined in (<ref>), f^o defined in (<ref>), H as in (<ref>) and R as in (<ref>). The following result held:    \n",
       "52.     R_l^-1 = ((f^o)^T)^-1R^-1 (f^o)^-1\n",
       "53.                   Proof of Lemma <ref>:      \n",
       "54.     R_l    𝔼[  ϵ_l ϵ_l^T  ]\n",
       "55.     R_l    = 𝔼[ f^o  ϵϵ^T (f^o)^T   ]\n",
       "56.      because the observations are uncorrelated, we have:      \n",
       "57.     R_l    = f^o  𝔼[  ϵϵ^T    ]  (f^o)^T\n",
       "58.     R_l    = f^o  R (f^o)^T\n",
       "59.     R_l^-1   = ((f^o)^T)^-1R^-1 (f^o)^-1\n",
       "60.           \n",
       "61. \n",
       "62.          Proof of Lemma <ref>: we use Lemmas 5 and 6 to give:     \n",
       "63.     A_l    = V_l^T  R_l^-1V_l\n",
       "64.        from (<ref>) and (<ref>), we have:       \n",
       "65.     A_l    = V^T H^T (f^o)^T    ((f^o)^T)^-1R^-1 (f^o)^-1 f^o HV\n",
       "66.      which gives the (<ref>).               Proof of Lemma <ref>:     \n",
       "67.     b_l    = V_l^T R_l^-1d_l\n",
       "68.               from (<ref>) and (<ref>), we have:              \n",
       "69.     b_l    = V^T H^T (f^o)^T ((f^o)^T)^-1R^-1 (f^o)^-1 f^o(d)\n",
       "70.      which gives the (<ref>).       This completes the proof that 𝐰^DA =   𝐰_l^DA. [/INST] \n",
       "\n",
       " True False False\n",
       "13</s><s>[INST]     "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d60bf-1d2d-41ff-965a-16b790f16292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d60e3-86d2-47c0-b953-e6b631255b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78765946-f2a6-45b0-89ef-353fa5cbddba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8a1df510-62c2-4b7d-82bc-34e5ffeb6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/network/scratch/w/weissmar/tn/info-bazaar/data/{category}/dataset_step_1_old.json\", \"r\") as f:\n",
    "    dataset_step_1 = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9c9e8668-520a-4dea-a0ba-04396def3cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nuggets = []\n",
    "for paper in dataset_step_1.values():\n",
    "    for block in paper['blocks']:\n",
    "        all_nuggets.extend(block.get('nuggets', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "eef94cb7-d689-45c2-b01a-dbb55ec20f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_nuggets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "2713474b-b323-43fd-87cc-ce4798d1ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "program_string = \"\"\"\n",
    "{{#system~}}\n",
    "You are an exam auditor. Your job is to reject bad questions. Respond with only the word \"True\" or the word \"False\". Emit True if the question is factual and could have universal agreement. Emit False if the question is ambiguous or makes specific references. Do not emit new lines.\n",
    "{{~/system}}\n",
    "    \n",
    "{{#user~}}\n",
    "{{nugget_strs}}\n",
    "{{~/user}}\n",
    "\n",
    "{{#assistant~}}\n",
    "{{#geneach 'answers' num_iterations=5}}{{gen 'this' max_tokens=1}}{{/geneach}}\n",
    "{{~/assistant}}\n",
    "\"\"\"\n",
    "# \n",
    "program_string = clean_program_string(program_string)\n",
    "program = guidance(program_string, llm=llm, silent=True)  # noqa\n",
    "nugget_strs = []\n",
    "for idx, i in enumerate(range(0, 9)):\n",
    "    nugget_strs.append(f\"{idx}. {all_nuggets[i]['question']}\")\n",
    "program_output = program(nugget_strs=nugget_strs)\n",
    "answer = program_output[\"answers\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "04ad5377-e259-402d-8884-233a266f7a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. What is the ranking of oil palm among oil crops in terms of planted area?',\n",
       " '1. What percentage of vegetable oil production did oil palm account for in 2019?',\n",
       " '2. Why is oil palm considered an attractive economic alternative in many tropical countries?',\n",
       " '3. What are the potential environmental impacts of large-scale oil palm production in Malaysia and Indonesia?',\n",
       " '4. What are some of the long-lasting effects of oil palm development on the environment?',\n",
       " '5. What have engineers developed to keep automated systems on course?',\n",
       " '6. What are researchers endeavoring to build?',\n",
       " '7. What is the fundamental principle behind capturing sequential information without distortion?',\n",
       " '8. What type of models have been used in control theory applications?']"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nugget_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "251beb2f-753a-4102-8312-8b7a7a3f5f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['True', '\\n', 'True', '\\n', 'False']"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program_output[\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9098cbe8-13b7-4c90-8ac3-6368c646e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tn",
   "language": "python",
   "name": "tn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
